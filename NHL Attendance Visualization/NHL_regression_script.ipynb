{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf77c45-41b1-4c29-ba5d-57a2cb708c76",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data\n",
    "Please see jupyter notebook tilted \"NHL_attendance_scrape\" to see the code for scraping the attedance of every regular season game from the 2018-19 season from Hockey Reference. I chose to analysis the 2018-19 season becuase that was the last full NHL season unaffected by Covid restrictions.\n",
    "\n",
    "x data points = Home Game\n",
    "\n",
    "y data points = Attendance\n",
    "\n",
    "Source: https://www.hockey-reference.com/leagues/NHL_2019_games.html\n",
    "\n",
    "*Note: A model for the Tampa Bay Lightning, Boston Bruins, Edmonton Oilers, and Winnipeg Jets will not generated from this dataset because according to Hockey Reference, they sold out every single home game each. Congrats to them, but there is no model for a vertical line*\n",
    "\n",
    "\n",
    "### Structure:\n",
    "1) Model and Error Propagation Function: \n",
    "- The first six functions define the linear, power and parabolic models and their error propagation formulas. These error propagation formula are used to generate the confidnce bands (CB) of the fit\n",
    "\n",
    "2) Plot type functions:\n",
    "- *Curve_Fit*: Use scipy to determine the best fit regression model base on given data. Plot the x and y data point with regression line and display the best fit coefficients. Call according error propagation function to plot CB. Plot the prediction band (using MSE). Calculate and display regression evaluation metrics eg, SSE, RMSE, R^2 (linear only) \n",
    "- *Resolution_plot*: Calculate the width of the CB at every point along the x axis to determine the prediction resolution at each point. I expect most of these plots to be empty becuase to calculate the width of the CB you should be able to draw a horizontal line intersecting both the upper and lower CB. However, there is so much variance in these regression fits, I doubt this will happen.\n",
    "- *Residual_Distribution_Plot*: Plot the residuals between the acutal attendance and the predicted attendnace vs the predicted attendance with the centre horizontal line represnted the regression line. There should be a normal distribution of resuduals surrounding the regression line. This distribution is indicated by a vertical histogram that will be sitting just right to the residual plot\n",
    "- *Russian_alphabet_plot*: AKA Kolmorgov-Smirnov goodness-of-fit test. The orange line is the Culmative Distribution Funcion (CDF) of a normal distribution and blue line is the empherical CDF of the selected regression line. A significance test can be performed on the separation between the normal and emphericla CDF. Where is the p-value is less than 0.05, we can condclude that the regression fit is not good. In practice this test has a low pass criteria and should be modified to be more strict.\n",
    "\n",
    "3) Create master figure:\n",
    "- Use the library gridspec to order all the plots onto on page per dataset.\n",
    "- Order of the plot on one is page is as follows:\n",
    "    - Top Left: Curve Fit Plot\n",
    "    - Top Right: Resolution Ploy\n",
    "    - Bottom Left: Residual Distribution Plot\n",
    "    - Bottom Middle: Histogram of Residual Ditsrubution \n",
    "    - Bottom Right; CDF plot and Kolmorgov-Smirnov Test\n",
    "\n",
    "4) Call All Functions\n",
    "- Import NHL_attendance data\n",
    "- Create excel to store all performance evaluation metrics\n",
    "- Loop through each team to create a subdataset to run through model generation and plotting\n",
    "- Save all figures to pdf (Ecpect 87 different pdfs. 29 teams x 3 model types)\n",
    "\n",
    "Overall, some sections of the code may seem inefficent. This is becuase these script was originally designed to hdanle datasets with much more parameters and user input selection\n",
    "\n",
    "**Scroll to the bottom to see data visulaization output and final conclusions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e9661a40-7396-4bb9-be3e-fd697796a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0facbe3d",
   "metadata": {},
   "source": [
    "## Model and Error Propagation Functions\n",
    "- power_model()\n",
    "- power_err_prop()\n",
    "- linear_model()\n",
    "- linear_err_prop()\n",
    "- parabolic_model()\n",
    "- parabolic_err_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e4e82f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from uncertainties import ufloat\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import kstest\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "import math\n",
    "from scipy.optimize import least_squares\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib as mpl\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5777a7bd-4916-4480-a1fd-4f66471cd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_model(x, alpha = 1, beta = 1, gamma = 0):\n",
    "    '''\n",
    "    Purpose: \n",
    "        Map an argument, x, to a response, y, with a power law relationship given by:   f(x) = y = coef*x^power + inercept\n",
    "        \n",
    "    Input:\n",
    "        x         (float - array) : The argument for the power law function\n",
    "        coef      (float)         : the coefficient in the power law function\n",
    "        power     (float)         : the exponent of the power law function\n",
    "        intercept (float)         : the intercept of the power law function\n",
    "    Output:\n",
    "        y         (float)         : The response of the argument, x, under the power law function/mapping\n",
    "    '''\n",
    "    \n",
    "    y = alpha*(x**beta) + gamma\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "05b5f7c7-6dcd-4c39-ad33-96b1ce0fe4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_err_prop(x, alpha, beta, gamma, cov):\n",
    "    '''\n",
    "    Purpose:\n",
    "        To compute the error propagation of a power-law curve. The terms use the typical error propagation formula, where each term is a product of partial derivatives\n",
    "        multiplied by the corresponding covariance term.\n",
    "        \n",
    "        The power-law function takes the form:   y = alpha*x^beta + gamma\n",
    "        \n",
    "    Input:\n",
    "        x     (array/float)    : argument to the power law function\n",
    "        alpha (float)          : alpha parameter (or its estimate) of the power-law function above\n",
    "        beta  (float)          : beta parameter (or its estimate) of the power-law function above\n",
    "        gamma (float)          : gamma parameter (or its estimate) of the power-law function above\n",
    "        cov   (2D array/float) : the covariance matrix of the three input parameters alpha, beta, gamma\n",
    "        \n",
    "    Output:\n",
    "        var_prop (array/float) : propagated error evaluated at the input argument\n",
    "    '''\n",
    "    \n",
    "    # Diagonal terms of the error prop:\n",
    "    \n",
    "    term_1 = np.power(x, 2*beta)*cov[0][0]\n",
    "    term_2 = np.power(alpha*np.log(x), 2.)*np.power(x, 2.*beta)*cov[1][1]                  \n",
    "    term_3 = cov[2][2]\n",
    "    \n",
    "    # Mixed terms of the error prop:\n",
    "    \n",
    "    term_4 = 2*alpha*np.power(x,2.*beta)*np.log(x)*cov[0][1]\n",
    "    term_5 = 2*np.power(x, beta)*cov[0][2]\n",
    "    term_6 = 2*alpha*np.power(x, 3.*beta)*np.log(x)*cov[1][2] \n",
    "    \n",
    "    var_prop = term_1 + term_2 + term_3 + term_4 + term_5 + term_6\n",
    "    \n",
    "    return var_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bc110c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(x, alpha, beta):\n",
    "    '''\n",
    "    Purpose: \n",
    "        Map an argument, x, to a response, y, with a power law relationship given by:   f(x) = y = alpha*x + beta\n",
    "        \n",
    "    Input:\n",
    "        x         (float - array) : The argument for the power law function\n",
    "        alpha     (float)         : the slope in the linear model\n",
    "        beta      (float)         : the intercept in the linear model\n",
    "       \n",
    "    Output:\n",
    "        y         (float)         : The response of the argument, x, under the linear model\n",
    "    '''\n",
    "    \n",
    "    y = alpha*x + beta\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "743c1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_err_prop(x, alpha, beta, cov):\n",
    "    \n",
    "    '''\n",
    "    Purpose:\n",
    "        To compute the error propagation of a linear curve. The terms use the typical error propagation formula, where each term is a product of partial derivatives\n",
    "        multiplied by the corresponding covariance term.\n",
    "        \n",
    "        The linear function takes the form:   y = alpha*x + beta\n",
    "        \n",
    "    Input:\n",
    "        x         (float - array) : The argument for the power law function\n",
    "        alpha     (float)         : the slope in the linear model\n",
    "        beta      (float)         : the intercept in the linear model\n",
    "        cov   (2D array/float) : the covariance matrix of the three input parameters alpha, beta, gamma\n",
    "        \n",
    "    Output:\n",
    "        var_prop (array/float) : propagated error evaluated at the input argument\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    # Diagonal terms of the error prop:\n",
    "    term_1 = np.power(x, 2)*cov[0][0]\n",
    "    term_2 = cov[1][1]\n",
    "    \n",
    "    # Mixed terms of the error prop:\n",
    "    term_3 = 2*x*cov[0][1]\n",
    "    \n",
    "    var_prop = term_1 + term_2 + term_3 \n",
    "    \n",
    "    return var_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "96341bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic_model(x, alpha, beta, gamma):\n",
    "    '''\n",
    "    Function : parabola\n",
    "    \n",
    "    Purpose  : Apply a parabolic function to the input argument, x, where parabola(x) = alpha*x^2 + beta*x + gamma\n",
    "    \n",
    "    Input: \n",
    "        x (float/array) : an array of floats to be used as an argument for the parabolic function \n",
    "        alpha (float)      : the coefficient for the second order term of the parabola \n",
    "        beat (float)      : the coefficient for the first order (linear) term of the parabola\n",
    "        gamma (float)      : the zeroth order (constant) term of the parabola\n",
    "        \n",
    "    Output:\n",
    "        y (float/array) : The mapping of the argument, x, under the parabolic function\n",
    "    '''\n",
    "    \n",
    "    t2 = alpha*(x**2.)\n",
    "    t1 = beta*x\n",
    "    \n",
    "    y = gamma + t1 + t2\n",
    "\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "892fc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola_error_prop(x, alpha,beta,gamma, cov):\n",
    "    '''\n",
    "    Purpose:\n",
    "        To compute the error propagation of a parabola whose coefficients have been estimated with some uncertainty. The terms use the typical error propagation formula, where each term is a product of partial derivatives\n",
    "        multiplied by the corresponding covariance term.\n",
    "        \n",
    "        The parabola function takes the form:   y = alpha*x^2 + beta*x + gamma\n",
    "        \n",
    "    Input:\n",
    "        x   (array/float)    : argument to the power law function\n",
    "        gamma  (float)          : zeroth order coeffcient (or its estimate) of the parabolic function above\n",
    "        beta  (float)          : first order coefficient (or its estimate) of the parabolic function above\n",
    "        alpha  (float)          : second order coefficient (or its estimate) of the parabolic function above\n",
    "        cov (2D array/float) : the covariance matrix of the three input parameters p0, p1, p2\n",
    "        \n",
    "    Output:\n",
    "        varprop (array/float) : propagated error evaluated at the input argument\n",
    "    '''\n",
    "    import numpy as np    \n",
    "        \n",
    "    # diagonal terms:\n",
    "    t1 = np.power(x, 4.)*cov[0][0]\n",
    "    t2 = np.power(x, 2.)*cov[1][1]\n",
    "    t3 = cov[2][2]\n",
    "    \n",
    "    # mixing terms:\n",
    "    t4 = 2*np.power(x, 3.)*cov[0][1]\n",
    "    t5 = 2*np.power(x, 2.)*cov[0][2]\n",
    "    t6 = 2*x*cov[1][2]\n",
    "    \n",
    "    # Combine for total variance:\n",
    "    varprop = t1 + t2 + t3 + t4 + t5 + t6\n",
    "    \n",
    "    return varprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09851901",
   "metadata": {},
   "source": [
    "## Plot types Functions\n",
    "- curvefit_plot\n",
    "- resolution_plot\n",
    "- residual_distribution_plot\n",
    "- russian_alphabet_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "81901a02-cab8-42da-8e45-ce82f0569c57",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def curvefit_plot(x_data, y_data, model,error_prop_model, model_choice, ax):\n",
    "#Best fit estimates and plot the curve with CB and PB\n",
    "    random.seed(12345)\n",
    "    \n",
    "    #Perform curve fit \n",
    "    bestest, covar = curve_fit(model, x_data, y_data)\n",
    "    sigma_est  = np.sqrt(np.diagonal(covar))\n",
    " \n",
    "    #Calculate residuals and stats\n",
    "    d_f = len(bestest)\n",
    "    \n",
    "    \n",
    "    predictions = model(x_data, *bestest)\n",
    "    res = y_data - predictions\n",
    "    sse = np.sum(res**2) #this is SSE \n",
    "    mse = sse/(len(y_data)-d_f)\n",
    "    rmse = math.sqrt(mse)\n",
    "    \n",
    "    ss_tot = np.sum((y_data-np.mean(y_data))**2)\n",
    "    r_squared = 1 - (sse / ss_tot)\n",
    "\n",
    "    n_ypoints = len(y_data)\n",
    "\n",
    "    predband_error = mse\n",
    "    \n",
    "\n",
    "    #Plotting\n",
    "    ####################################################################\n",
    "    #fig, ax = plt.subplots(figsize = (16.18, 10))\n",
    "    \n",
    "    band_x = np.linspace(min(x_data), max(x_data), 300)  \n",
    "    \n",
    "    predictions_plot = model(band_x, *bestest)\n",
    "    \n",
    "    # plot the data points:\n",
    "    ax.scatter(x_data, y_data, facecolor = 'silver',edgecolor = 'k', s = 10, alpha = 1)\n",
    "    \n",
    "    # plot the model:\n",
    "    ax.plot(band_x, predictions_plot, 'black') # regression line\n",
    "    \n",
    "    #Plot the CB \n",
    "    bound_upper = predictions_plot + scipy.stats.t.ppf(0.975, n_ypoints-d_f)*np.sqrt(error_prop_model(band_x, *bestest, covar)) # upper edge of confidence band\n",
    "    bound_lower = predictions_plot - scipy.stats.t.ppf(0.975, n_ypoints-d_f)*np.sqrt(error_prop_model(band_x, *bestest, covar)) # lower edge of confidence band\n",
    "    bound_lower = np.array(bound_lower, dtype=float)\n",
    "    bound_upper = np.array(bound_upper, dtype=float)\n",
    "    \n",
    "    ax.plot(band_x, bound_upper, linewidth = 2, alpha = 0.4, color = 'cyan')\n",
    "    ax.plot(band_x, bound_lower, linewidth = 2, alpha = 0.4, color = 'cyan')\n",
    "    ax.fill_between(band_x, bound_lower, bound_upper, color = 'cyan', alpha = 0.1, label = 'Confidence Band') \n",
    "\n",
    "    # Add prediction band edges:\n",
    "    pred_bound_upper = predictions_plot + scipy.stats.t.ppf(0.975, n_ypoints-d_f)*np.sqrt(error_prop_model(band_x, *bestest, covar) + predband_error) # upper edge of confidence band\n",
    "    pred_bound_lower = predictions_plot - scipy.stats.t.ppf(0.975, n_ypoints-d_f)*np.sqrt(error_prop_model(band_x, *bestest, covar) + predband_error)\n",
    "    ax.plot(band_x,pred_bound_upper, color = 'green', linestyle = '--', linewidth = 1, label = 'Prediction Band')\n",
    "    ax.plot(band_x,pred_bound_lower, color = 'green', linestyle = '--', linewidth = 1)\n",
    "\n",
    "    # Axes labels and title:\n",
    "    ax.set_ylabel('Attendance', fontsize=16, rotation = 'vertical')\n",
    "    #ax.yaxis.set_label_coords(-0.07,0.5)\n",
    "    ax.set_xlabel('Home Game', fontsize = 16)\n",
    "    ax.set_title('Curve Fit', fontsize = 20)\n",
    "    \n",
    "\n",
    "    # Adjust the frame of the plot:\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['top'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['right'].set_color('black')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    ax.grid(alpha = 0.2)\n",
    "    \n",
    "    \n",
    "    # place a text box in upper left in axes coords:\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    \n",
    "    sigma_est  = np.sqrt(np.diagonal(covar))\n",
    "    list_of_coeff =['alpha','beta','gamma']\n",
    "    \n",
    "    coeff_output = ''\n",
    "    for coeff in range(len(bestest)):\n",
    "        coeff_estimate = '{} = {}\\n'.format(list_of_coeff[coeff],ufloat(bestest[coeff], sigma_est[coeff]) )\n",
    "        coeff_output = coeff_output + coeff_estimate\n",
    "        \n",
    "    ax.text(0.05, 0.95, 'Best Fit Coefficients\\n--------------------------------\\n'+coeff_output, transform=ax.transAxes, fontsize=16,verticalalignment='top', bbox=props)\n",
    "    \n",
    "\n",
    "    if model_choice == '1': #If linear model, use r^2 value   \n",
    "        sse_r2_text = np.round(r_squared,4)\n",
    "    else: #If Parabolic or power use sse value\n",
    "        sse_r2_text = np.round(sse,4)\n",
    "        \n",
    "    ax.text(0.05, 0.7, 'RMSE: {} \\nSSE or R^2: {} \\nn = {}'.format(np.round(rmse,4) ,  sse_r2_text, n_ypoints), transform=ax.transAxes, fontsize=16,verticalalignment='top', bbox=props)\n",
    "    \n",
    "    # annnnnd the legend:\n",
    "    ax.legend(loc = 'lower right', fontsize = 16)\n",
    "\n",
    "    \n",
    "    return bestest, predband_error, covar, res, predictions, sse_r2_text, rmse, coeff_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9b879133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_plot (model, err_prop_model, bestest, covar, predband_error, y_data,x_data, ax):\n",
    "#Calculate the relative resolution and plot    \n",
    "    n_ypoints = len(y_data)\n",
    "    d_f = len(bestest)\n",
    "    \n",
    "    current_range = np.linspace(min(y_data)*0.9, max(y_data)*1.1, 1000)\n",
    "    from scipy.optimize import fsolve\n",
    "    band_conc = np.linspace(-10, 10, 10000)\n",
    "    spreads = []\n",
    "    estimates = []\n",
    "    \n",
    "    \n",
    "    initial_guess = (x_data.min() + x_data.max())/2\n",
    "    \n",
    "    \n",
    "    for current in current_range:\n",
    "        def best_model_upper(x):\n",
    "            return model(x, *bestest) + scipy.stats.t.ppf(0.975, n_ypoints-d_f)*np.sqrt(err_prop_model(x, *bestest, covar) + predband_error) - current \n",
    "\n",
    "        def best_model_lower(x):\n",
    "            return model(x, *bestest) - scipy.stats.t.ppf(0.975, n_ypoints-d_f)*np.sqrt(err_prop_model(x, *bestest, covar) + predband_error) - current \n",
    "\n",
    "        def best_model(x):\n",
    "            return model(x, *bestest) - current \n",
    "\n",
    "        \n",
    "        \n",
    "        root_low = least_squares(best_model_upper, bounds = (x_data.min(), x_data.max()), x0 = initial_guess)\n",
    "        root_low_x = root_low.x\n",
    "        root_low_cost = root_low.cost\n",
    "        # the second argument is just an initial guess that is about midway through our range and is also                                                                                         \n",
    "        # recognizable as the default result due to its obvious pattern.\n",
    "        root_upp = least_squares(best_model_lower, bounds = (x_data.min(), x_data.max()), x0 = initial_guess)\n",
    "        root_upp_x = root_upp.x\n",
    "        root_upp_cost = root_upp.cost\n",
    "        \n",
    "        cost_limit = 10**(-10)\n",
    "        \n",
    "        estimate = least_squares(best_model, bounds = (x_data.min(), x_data.max()), x0 = initial_guess).x    \n",
    "        \n",
    "        #Check any case the cost of least squares is gretaer then limit. This means there is likely no proper real solution \n",
    "        if ((root_upp_cost > cost_limit) | (root_low_cost > cost_limit)):\n",
    "            continue\n",
    "            \n",
    "        else:      \n",
    "            estimates.append(estimate)\n",
    "            spread = root_upp_x - root_low_x\n",
    "            spreads.append(spread/estimate*100)\n",
    "\n",
    "\n",
    "    #plot the labels, target resolution and spines of the resolution plot\n",
    "    \n",
    "    target_resolution = 10\n",
    "    \n",
    "\n",
    "    ax.set_ylabel('Resolution(%)', fontsize=16, rotation = 'vertical')\n",
    "\n",
    "    ax.set_xlabel('Home Game', fontsize = 16)\n",
    "    \n",
    "    ax.set_title('Relative Resolution (Width of CI / Estimate)', fontsize = 20)\n",
    "    \n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['top'].set_color('black')\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['right'].set_color('black')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Create a case where the estimates is empty \n",
    "    \n",
    "    if not estimates:\n",
    "        final_text = 'No intersection between the upper and lower prediction bands'\n",
    "        ax.text(0.05, 0.95, final_text, transform=ax.transAxes, fontsize=16,verticalalignment='top', bbox=props)\n",
    "\n",
    "    else: \n",
    "        ax.scatter(estimates, spreads, s = 3)\n",
    "        res_goal = list(filter(lambda x : x[0]<10 ,spreads))\n",
    "        \n",
    "        max_y = max(spreads)*1.05\n",
    "        max_x = max(estimates)*1.05\n",
    "        min_x = min(estimates)*0.95\n",
    "        \n",
    "        ax.axvline(x=estimates[np.argmin(spreads)], ymin=0, ymax = min(spreads)/max_y, linewidth = 3, c = 'pink')\n",
    "\n",
    "   \n",
    "    \n",
    "        ax.set_xlim(min_x, max_x)\n",
    "    \n",
    "       \n",
    "        final_text = 'Min Res (%)'.format(np.round(min(spreads)[0], 2), np.round(estimates[np.argmin(spreads)][0],2))\n",
    "    \n",
    "\n",
    "        \n",
    "        ax.text(0.05, 0.95, final_text, transform=ax.transAxes, fontsize=16,verticalalignment='top', bbox=props)\n",
    "\n",
    "        \n",
    "        \n",
    "    ax.grid(alpha = 0.2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5580f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_distribution_plot(res, predictions, ax1, ax2):\n",
    "#Create the residual plot and residual histogram\n",
    "\n",
    "    num_bins = 15\n",
    "\n",
    "    x_bins = (predictions.max()-predictions.min())/num_bins\n",
    "    \n",
    "    start = predictions.min()\n",
    "    full_bins=[]\n",
    "    center_list=[]\n",
    "    \n",
    "    #This for loop will calculate the sum or residuals vs. Concentration line trend\n",
    "    #Maybe build in the user option to turn this line on or off. Dont know how useful it can be\n",
    "    for b in range(num_bins+1):\n",
    "        \n",
    "        end = start+x_bins\n",
    "        center = start+x_bins/2\n",
    "        bin_i = []\n",
    "        \n",
    "        for i in predictions.index:\n",
    "            \n",
    "            if start <= predictions[i] <= end:\n",
    "                \n",
    "                bin_i.append(res[i])\n",
    "        \n",
    "        full_bins.append(np.sum(bin_i))  \n",
    "        center_list.append(center)\n",
    "        start = end\n",
    "    \n",
    "    #Plot the residual plot on ax1 \n",
    "    ax1.scatter(predictions, res)\n",
    "    ax1.axhline(0, c = 'black', linewidth = 3, label = 'Regression Line')\n",
    "    #ax1.plot(center_list, full_bins, color = 'green', lw=2,alpha = 0.6, label ='Sum of Residuals Plot')\n",
    "    ax1.set_xlabel('Attendance Estimates',fontsize=16)\n",
    "    ax1.set_ylabel('Residuals', fontsize=16)\n",
    "    ax1.legend(loc = 'upper right', fontsize = 16)\n",
    "    ax1.set_title('Residual Plot', fontsize = 20)\n",
    "    ax1.spines['left'].set_color('black')\n",
    "    ax1.spines['top'].set_color('black')\n",
    "    ax1.spines['bottom'].set_color('black')\n",
    "    ax1.spines['right'].set_color('black')\n",
    "    ax1.tick_params(axis='both', labelsize=14)\n",
    "    ax1.grid(visible=True, alpha = 0.2)\n",
    "    \n",
    "    #Plot the residual histogram on ax2\n",
    "    ax2.hist(res, orientation = 'horizontal', edgecolor = 'black', lw=1)\n",
    "    ax2.spines['left'].set_color('black')\n",
    "    ax2.spines['top'].set_color('black')\n",
    "    ax2.spines['bottom'].set_color('black')\n",
    "    ax2.spines['right'].set_color('black')\n",
    "    ax2.tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bc457193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_alphabet_plot(res,ax):\n",
    "#Perform K-s test and graoh residuals cdf vs a normal cdf\n",
    "\n",
    "    #Standardize the residuals\n",
    "    mean = np.mean(res)\n",
    "    std = np.std(res)\n",
    "    \n",
    "    stand_res =[]\n",
    "    for x in res:\n",
    "        z = (x - mean)/std\n",
    "        stand_res.append(z)\n",
    "    \n",
    "    #Calculate the residuals cdf\n",
    "    x_res = np.sort(stand_res)\n",
    "    res_cdf = np.arange(len(stand_res))/len(stand_res)\n",
    "    \n",
    "    #Calcuate the normal cdf\n",
    "    x_range = np.linspace(-3,3,1000)\n",
    "    normal_cdf = stats.norm.cdf(x_range, 0, 1)\n",
    "    \n",
    "    ax.plot(x_res, res_cdf,marker='o', label = 'Residuals CDF')\n",
    "    ax.plot(x_range ,normal_cdf, label = 'Normal CDF')\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.set_title('CDF Plot', fontsize =20)\n",
    "    ax.set_ylabel('Probability', rotation ='vertical', fontsize = 16)\n",
    "    ax.set_xlabel('Residuals', fontsize =16)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    ax.legend(loc = 'lower right', fontsize = 16)\n",
    "    \n",
    "    #Perfrom K-S test\n",
    "    result = kstest(stand_res,'norm')\n",
    "    \n",
    "    p_value = 0.05\n",
    "    \n",
    "    if result[1] > p_value:\n",
    "        ks_text = 'P-Value: {} \\nK-S Test: Pass'.format(np.round(result[1],3))\n",
    "    else:\n",
    "        ks_text = 'P-Value: {} \\nK-S Test: Fail'.format(np.round(result[1],3))\n",
    "        \n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.05, 0.95, ks_text, transform=ax.transAxes, fontsize=18,verticalalignment='top', bbox=props)\n",
    "    ax.grid(visible=True, alpha =0.2)\n",
    "    \n",
    "    return ks_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcc77b",
   "metadata": {},
   "source": [
    "## Create Master Figure using GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "88b6e82e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def master_figure(x_data,y_data, model, title):\n",
    "#Define the dictionaries to call each model and create the master figure using gridspec\n",
    "\n",
    "    model_dict = {'1' : linear_model, '2': power_model, '3':parabolic_model} \n",
    "    error_prop_dict = {'1' : linear_err_prop, '2': power_err_prop, '3':parabola_error_prop}\n",
    "    \n",
    "    reg_model = model_dict[model]\n",
    "    error_prop_model = error_prop_dict[model]\n",
    "    \n",
    "    master_fig = plt.figure(figsize=(30,20))\n",
    "    spec = mpl.gridspec.GridSpec(ncols=6, nrows=2,wspace=0.25,hspace=0.2) # 6 columns evenly divides both 2 & 3\n",
    "\n",
    "    ax1 = master_fig.add_subplot(spec[0,0:3]) # row 0 with axes spanning 2 cols on evens\n",
    "    ax2 = master_fig.add_subplot(spec[0,3:6])\n",
    "    ax3 = master_fig.add_subplot(spec[1,0:2])\n",
    "    ax4 = master_fig.add_subplot(spec[1,2:3], sharey = ax3)# row 0 with axes spanning 2 cols on odds\n",
    "    ax5 = master_fig.add_subplot(spec[1,3:6])\n",
    "\n",
    "    #Executing all graphing functions\n",
    "    bestest , predband_error , covar, res, predictions, sse_r2_text,rmse, coeff_output  = curvefit_plot(x_data, y_data, reg_model, error_prop_model, model, ax1)\n",
    "    resolution = resolution_plot(reg_model,error_prop_model, bestest, covar, predband_error, y_data, x_data, ax2)\n",
    "    residual_distribution_plot(res, predictions,ax3, ax4)\n",
    "    ks_text = russian_alphabet_plot(res,ax5)\n",
    "    \n",
    "    master_fig.suptitle( title, fontsize = 26, y=0.92)\n",
    "    \n",
    "    plt.show(master_fig)\n",
    "    \n",
    "    return master_fig, ks_text, coeff_output, sse_r2_text, rmse , resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b891c13",
   "metadata": {},
   "source": [
    "## Call All Functions\n",
    "- import NHL_attendance data\n",
    "- create excel to store all performance evaluation metrics\n",
    "- loop through each team to create a subdataset to run through models generation\n",
    "- Save all figures to pdf (Expect 90 different pdfs. 30 teams x 3 model types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f55f4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_evaluation_main():\n",
    "    \n",
    "    model_names = {'1' : 'Linear Model', '2': 'Power Model', '3':'Parabolic Model'}\n",
    "    model_table = ['Linear Model', 'Power Model', 'Parabolic Model']\n",
    "    model_selection = ['1', '2', '3']\n",
    "    \n",
    "    evaluation = ['K-S Test' ,'Coeificents','SSE/R^2','RMSE','Resolution' ]\n",
    "    \n",
    "\n",
    "    \n",
    "    attendance_data = pd.read_csv('../NHL attendance/NHL_attendance_df.csv')\n",
    "    attendance_data['Att.'] = attendance_data['Att.'].apply(lambda x: float(x.replace(',','')))\n",
    "    attendance_data['Home Game'] = attendance_data['Home Game'].apply(lambda x: float(x))\n",
    "    #Now setup the output table                               \n",
    "    ##############################################################################    \n",
    "    \n",
    "    attributes = list(attendance_data['Home'].unique())\n",
    "    \n",
    "    #Create multi-index lables for output tables\n",
    "    column_labels = pd.MultiIndex.from_product([model_table, evaluation])\n",
    "    index_labels = pd.MultiIndex.from_product([attributes])\n",
    "\n",
    "    curve_metrics = pd.DataFrame(columns = column_labels, index = index_labels)\n",
    "                            \n",
    "    #Perform curve fitting\n",
    "    ######################################################\n",
    "    fig_list =[]\n",
    "\n",
    "    for team in attributes:\n",
    "        \n",
    "        team_data = attendance_data[attendance_data['Home'] == team]     \n",
    "        if len(team_data['Att.'].unique()) != 1:\n",
    "            for model in model_selection:\n",
    "                \n",
    "                                 \n",
    "                title = 'Dataset: {} - {}'.format(team,model_names[model])\n",
    "                \n",
    "                y_data = team_data['Att.']\n",
    "                x_data = team_data['Home Game']            \n",
    "\n",
    "            \n",
    "                try:\n",
    "                    master_fig, ks_test, coeff_output, sse_r2_text, rmse , resolution =  master_figure(x_data, y_data, model, title)\n",
    "            \n",
    "                    curve_metrics.loc[team,(model_names[model],'K-S Test')]= ks_test             \n",
    "                    curve_metrics.loc[team,(model_names[model],'Resolution')]= resolution\n",
    "                    curve_metrics.loc[team,(model_names[model],'SSE/R^2')]= sse_r2_text\n",
    "                    curve_metrics.loc[team,(model_names[model],'RMSE')]= rmse\n",
    "                    curve_metrics.loc[team,(model_names[model],'Coeificents')]= coeff_output\n",
    "                \n",
    "                    fig_list.append(master_fig)\n",
    "                    \n",
    "                \n",
    "                except RuntimeError:  \n",
    "                    print ('No solution {}, - {}'.format(model_names[model],team))  \n",
    "        else:\n",
    "            print('Team {} has sold out every single game. There is resulting model'.format(team))\n",
    "    \n",
    "    #Save graph plus output table\n",
    "    #This probably should be its own function\n",
    "    ####################################################\n",
    "    \n",
    "    \n",
    "    title_main = 'NHL_attendnace_Curve_Fit'\n",
    "        \n",
    "    pp = PdfPages('../NHL attendance' + '/' + title_main + '.pdf')\n",
    "    for i in fig_list:\n",
    "        pp.savefig(i)\n",
    "    pp.close()\n",
    "    \n",
    "    curve_metrics.to_excel('../NHL attendance' + '/Curve_Metrics.xlsx' )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a2ee5",
   "metadata": {},
   "source": [
    "## Run the Code\n",
    "\n",
    "### Please view visualization output in 'NHL_attendance_vis' PDF.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d268d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curve_evaluation_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d365f4",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "As expected none of these regression model fit the attendance data well. \n",
    "\n",
    "It can be seen that the confidence bands flair our dramatically. This is becuase the derivateion of the error propagation forumla for power model has large exponetial term that expand quickly when fitting data that does follow a power law. In some cases the power model didn't even converge to a solution\n",
    "\n",
    "In any case, I will demostrate how you could interpret these plots and metrics to efficiently evlauate and compare the models.\n",
    "\n",
    "**Example - St.Louis Blues Parabolic Model**\n",
    "1) Check if a parabolic model accurate describes the realationship in this dataset. Tools to use: Curve Plot, residuals plot and CDF plot\n",
    "- First we examine the Curve fit of the linear model to qualitativley see if the regression line is passing through the centre of the distribution of points, whcih appears to be in this case. We can also qualitatively examine the behavoir of the Confidence and Prediction Bands\n",
    "- Next look at the residual plot to see if the distribution of residuals around the regression line is normal. This affirms the regression model is accurately pasisng through the middle of the distribution of points. Thus we can conclude a parabolic model is appropraite for this datatset. \n",
    "- The CDF plot demonstarte that the CDF of the model accurate follows the CDF of a normal distribution, thus passing the Kolmorgov-Smirnov test. A final check to affirm a paraboloc fit is correct for this data\n",
    "\n",
    "2) Compare the quality of this fit to other models. Tools to use: Resolution Plot, Curve Metrics RMSE, SEE and R^2, Uncertancy of Best Fit Coefficients. These values are also stored and eaily comparable in the excel file 'Cuve_Metrics' \n",
    "- Resolution plot can be used to compare the width of CB between differnt models correlating to the uncertancy of the regression fit. However, this tool cannot be used in this case becuase no model has stable enough CB wehere a horizontal line crosses both the upper and lower CB\n",
    "- The uncertanicy (+/-) On the best coeifficent can also be used to evlaute the uncertancy of the regression fit.\n",
    "- Metrics such as RMSE and SSE explain the error between the actual attendnace values and the regression line. The smaller the emtric indicates a better fit. RMSE can be used to compare between Linear, Parabolic and Power model, while SSE can only be compared between Parabolic and Power model. \n",
    "- R^2 is a more robost goodness-of-fit test for linear model. Where the closer r^2 is to 1.0 indicated a linear fit that describes all the varinace in the dataset, this value can nly be used to compare R^2 values. \n",
    "- However, these mtrics could be interpreted in different wasy based on the domain and application of the data\n",
    "- In this case, the St.Louis Blues Parabolic Model has middle of the pack RMSE and SSE valus. So maybe this fit is lower quality then originally thought\n",
    "\n",
    "3) Back to Reality\n",
    "\n",
    "Why would the St.Louis Blues 2018-19 season regular season home attendance follow an upwards parabolic model?\n",
    "\n",
    "This was the year the Bluse went from last place in the NHL on January 1st, to winning the Stanely Cup on the back of breakout goaltender Jordan Binnington\n",
    "Pretty cool we can see this in the data!\n",
    "\n",
    "_________________\n",
    "\n",
    "I hope this demonstrated how useful this data visulization tool *can* be when generating and comparing regression fits for data that actually closly reflect a linear, parabolic or power model. This script provides the tools to select a superior model from fits that seemingly have very little difference. \n",
    "\n",
    "Thanks for visiting my project!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14adf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
